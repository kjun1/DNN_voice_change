{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sidekit\n",
    "import os\n",
    "import sys\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as mpl\n",
    "import logging\n",
    "import re\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "idmap = sidekit.IdMap()\n",
    "#idmap.leftids = np.array([str(i) for i, j in itertools.product(range(1,101), range(1,101))])\n",
    "#idmap.rightids = np.array([\"{}/{}\".format(i,j) for i, j in itertools.product(range(1,101), range(1,101))])\n",
    "idmap.leftids = np.array([\"1\",\"2\",\"2\",\"3\",\"3\"])\n",
    "idmap.rightids = np.array([\"1/2\",\"2/1\",\"2/2\",\"3/1\",\"3/2\"])\n",
    "idmap.start = np.empty(len(idmap.leftids), dtype=\"|O\")\n",
    "idmap.stop = np.empty(len(idmap.leftids), dtype=\"|O\")\n",
    "\n",
    "idmap.validate()\n",
    "idmap.write('task/3sesspwd_eval_m_trn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 9,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " 10,\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i, j in itertools.product(range(1,101), range(1,101))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = sidekit.Key()\n",
    "key.modelset =  np.array([1,2,3])\n",
    "key.segset =  idmap.rightids\n",
    "key.tar = np.zeros((3,5), dtype='bool')\n",
    "key.tar[0, 0] = True\n",
    "key.tar[0, 1:3] = True\n",
    "key.tar[2, 3:5] = True\n",
    "#print(key.tar)\n",
    "key.non = np.logical_not(key.tar)\n",
    "\n",
    "key.validate()\n",
    "key.write('task/3sess-pwd_eval_m_key.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndx = key.to_ndx()\n",
    "ndx.write('task/3sess-pwd_eval_m_ndx.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubmList = [str(x) + \"/10\" for x in range(8,10)]\n",
    "with open('task/ubm_list.txt','w') as of:\n",
    "    of.write(\"\\n\".join(ubmList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribNb = 512\n",
    "rsr2015Path = './'\n",
    "\n",
    "# Default for RSR2015\n",
    "audioDir = os.path.join(rsr2015Path , 'data')\n",
    "\n",
    "# Automatically set the number of parallel process to run.\n",
    "# The number of threads to run is set equal to the number of cores available\n",
    "# on the machine minus one or to 1 if the machine has a single core.\n",
    "nbThread = max(multiprocessing.cpu_count()-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load task definition\n"
     ]
    }
   ],
   "source": [
    "print('Load task definition')\n",
    "enroll_idmap = sidekit.IdMap('task/3sesspwd_eval_m_trn.h5')\n",
    "test_ndx = sidekit.Ndx('task/3sess-pwd_eval_m_ndx.h5')\n",
    "key = sidekit.Key('task/3sess-pwd_eval_m_key.h5')\n",
    "with open('task/ubm_list.txt') as inputFile:\n",
    "    ubmList = inputFile.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 750, in save_list\n",
      "    self.save(show, channel, audio_file, feature_file, noise_file, snr, reverb_file, reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 468, in save\n",
      "    reverb_level=reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 340, in extract\n",
      "    self.compressed)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1355, in write_hdf5\n",
      "    label)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1236, in _write_show_percentile\n",
      "    _add_percentile_dataset(fh, show + '/cep', cep)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 998, in _add_percentile_dataset\n",
      "    _add_dataset_header(fh, dataset_id, _min_val, _range, _header)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 972, in _add_dataset_header\n",
      "    fletcher32=True)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/group.py\", line 153, in create_dataset\n",
      "    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/dataset.py\", line 134, in make_new_dset\n",
      "    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 87, in h5py.h5d.create\n",
      "ValueError: Unable to create dataset (name already exists)\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 750, in save_list\n",
      "    self.save(show, channel, audio_file, feature_file, noise_file, snr, reverb_file, reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 468, in save\n",
      "    reverb_level=reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 340, in extract\n",
      "    self.compressed)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1355, in write_hdf5\n",
      "    label)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1236, in _write_show_percentile\n",
      "    _add_percentile_dataset(fh, show + '/cep', cep)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 998, in _add_percentile_dataset\n",
      "    _add_dataset_header(fh, dataset_id, _min_val, _range, _header)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 972, in _add_dataset_header\n",
      "    fletcher32=True)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/group.py\", line 153, in create_dataset\n",
      "    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/dataset.py\", line 134, in make_new_dset\n",
      "    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 87, in h5py.h5d.create\n",
      "ValueError: Unable to create dataset (name already exists)\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 750, in save_list\n",
      "    self.save(show, channel, audio_file, feature_file, noise_file, snr, reverb_file, reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 468, in save\n",
      "    reverb_level=reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 340, in extract\n",
      "    self.compressed)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1355, in write_hdf5\n",
      "    label)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1236, in _write_show_percentile\n",
      "    _add_percentile_dataset(fh, show + '/cep', cep)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 998, in _add_percentile_dataset\n",
      "    _add_dataset_header(fh, dataset_id, _min_val, _range, _header)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 972, in _add_dataset_header\n",
      "    fletcher32=True)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/group.py\", line 153, in create_dataset\n",
      "    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/dataset.py\", line 134, in make_new_dset\n",
      "    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 87, in h5py.h5d.create\n",
      "ValueError: Unable to create dataset (name already exists)\n",
      "Process Process-1:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 750, in save_list\n",
      "    self.save(show, channel, audio_file, feature_file, noise_file, snr, reverb_file, reverb_level)\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 468, in save\n",
      "    reverb_level=reverb_level)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 750, in save_list\n",
      "    self.save(show, channel, audio_file, feature_file, noise_file, snr, reverb_file, reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 340, in extract\n",
      "    self.compressed)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 468, in save\n",
      "    reverb_level=reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1355, in write_hdf5\n",
      "    label)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 340, in extract\n",
      "    self.compressed)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1236, in _write_show_percentile\n",
      "    _add_percentile_dataset(fh, show + '/cep', cep)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1355, in write_hdf5\n",
      "    label)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 998, in _add_percentile_dataset\n",
      "    _add_dataset_header(fh, dataset_id, _min_val, _range, _header)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1236, in _write_show_percentile\n",
      "    _add_percentile_dataset(fh, show + '/cep', cep)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 972, in _add_dataset_header\n",
      "    fletcher32=True)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 998, in _add_percentile_dataset\n",
      "    _add_dataset_header(fh, dataset_id, _min_val, _range, _header)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/group.py\", line 153, in create_dataset\n",
      "    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 972, in _add_dataset_header\n",
      "    fletcher32=True)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/dataset.py\", line 134, in make_new_dset\n",
      "    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/group.py\", line 153, in create_dataset\n",
      "    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/dataset.py\", line 134, in make_new_dset\n",
      "    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 87, in h5py.h5d.create\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "ValueError: Unable to create dataset (name already exists)\n",
      "  File \"h5py/h5d.pyx\", line 87, in h5py.h5d.create\n",
      "Process Process-4:\n",
      "ValueError: Unable to create dataset (name already exists)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 750, in save_list\n",
      "    self.save(show, channel, audio_file, feature_file, noise_file, snr, reverb_file, reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 468, in save\n",
      "    reverb_level=reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 340, in extract\n",
      "    self.compressed)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1355, in write_hdf5\n",
      "    label)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1236, in _write_show_percentile\n",
      "    _add_percentile_dataset(fh, show + '/cep', cep)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 998, in _add_percentile_dataset\n",
      "    _add_dataset_header(fh, dataset_id, _min_val, _range, _header)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 972, in _add_dataset_header\n",
      "    fletcher32=True)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/group.py\", line 153, in create_dataset\n",
      "    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/dataset.py\", line 134, in make_new_dset\n",
      "    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 87, in h5py.h5d.create\n",
      "ValueError: Unable to create dataset (name already exists)\n",
      "Process Process-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 297, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/jun/.pyenv/versions/3.7.4/lib/python3.7/multiprocessing/process.py\", line 99, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 750, in save_list\n",
      "    self.save(show, channel, audio_file, feature_file, noise_file, snr, reverb_file, reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 468, in save\n",
      "    reverb_level=reverb_level)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/features_extractor.py\", line 340, in extract\n",
      "    self.compressed)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1355, in write_hdf5\n",
      "    label)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 1236, in _write_show_percentile\n",
      "    _add_percentile_dataset(fh, show + '/cep', cep)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 998, in _add_percentile_dataset\n",
      "    _add_dataset_header(fh, dataset_id, _min_val, _range, _header)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/frontend/io.py\", line 972, in _add_dataset_header\n",
      "    fletcher32=True)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/group.py\", line 153, in create_dataset\n",
      "    dsid = dataset.make_new_dset(group, shape, dtype, data, name, **kwds)\n",
      "  File \"/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/h5py/_hl/dataset.py\", line 134, in make_new_dset\n",
      "    dset_id = h5d.create(parent.id, name, tid, sid, dcpl=dcpl)\n",
      "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
      "  File \"h5py/h5d.pyx\", line 87, in h5py.h5d.create\n",
      "ValueError: Unable to create dataset (name already exists)\n"
     ]
    }
   ],
   "source": [
    "logging.info(\"Initialize FeaturesExtractor\")\n",
    "extractor = sidekit.FeaturesExtractor(audio_filename_structure=audioDir+\"/{}.wav\",\n",
    "                                      feature_filename_structure=\"./features/{}.h5\",\n",
    "                                      sampling_frequency=16000,\n",
    "                                      lower_frequency=133.3333,\n",
    "                                      higher_frequency=6955.4976,\n",
    "                                      filter_bank=\"log\",\n",
    "                                      filter_bank_size=40,\n",
    "                                      window_size=0.025,\n",
    "                                      shift=0.01,\n",
    "                                      ceps_number=19,\n",
    "                                      vad=\"snr\",\n",
    "                                      snr=40,\n",
    "                                      pre_emphasis=0.97,\n",
    "                                      save_param=[\"vad\", \"energy\", \"cep\"],\n",
    "                                      keep_all_features=False)\n",
    "\n",
    "# Get the complete list of features to extract\n",
    "show_list = np.unique(np.hstack([ubmList, enroll_idmap.rightids, np.unique(test_ndx.segset)]))\n",
    "channel_list = np.zeros_like(show_list, dtype = int)\n",
    "logging.info(\"Extract features and save to disk\")\n",
    "extractor.save_list(show_list=show_list,\n",
    "                    channel_list=channel_list,\n",
    "                    num_thread=nbThread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a FeaturesServer to load features and feed the other methods\n",
    "features_server = sidekit.FeaturesServer(features_extractor=None,\n",
    "                                         feature_filename_structure=\"./features/{}.h5\",\n",
    "                                         sources=None,\n",
    "                                         dataset_list=[\"energy\", \"cep\", \"vad\"],\n",
    "                                         mask=None,\n",
    "                                         feat_norm=\"cmvn\",\n",
    "                                         global_cmvn=None,\n",
    "                                         dct_pca=False,\n",
    "                                         dct_pca_config=None,\n",
    "                                         sdc=False,\n",
    "                                         sdc_config=None,\n",
    "                                         delta=True,\n",
    "                                         double_delta=True,\n",
    "                                         delta_filter=None,\n",
    "                                         context=None,\n",
    "                                         traps_dct_nb=None,\n",
    "                                         rasta=True,\n",
    "                                         keep_all_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Train the UBM by EM')\n",
    "# Extract all features and train a GMM without writing to disk\n",
    "#ubm = sidekit.Mixture()\n",
    "#llk = ubm.EM_split(features_server, ubmList, distribNb, num_thread=nbThread, save_partial=True)\n",
    "#ubm.write('gmm/ubm.h5')\n",
    "ubm = sidekit.Mixture(\"./gmm/ubm.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute the sufficient statistics\n"
     ]
    }
   ],
   "source": [
    "print('Compute the sufficient statistics')\n",
    "# Create a StatServer for the enrollment data and compute the statistics\n",
    "enroll_stat = sidekit.StatServer(enroll_idmap,\n",
    "                                 distrib_nb=distribNb,\n",
    "                                 feature_size=60)\n",
    "enroll_stat.accumulate_stat(ubm=ubm,\n",
    "                            feature_server=features_server,\n",
    "                            seg_indices=range(enroll_stat.segset.shape[0]),\n",
    "                            num_thread=nbThread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP adaptation of the speaker models\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jun/.local/share/virtualenvs/dnn_voice_change-vie6OHFl/lib/python3.7/site-packages/sidekit/statserver.py:1085: RuntimeWarning: invalid value encountered in true_divide\n",
      "  M = modelStat.stat1 / modelStat.stat0[:, index_map]\n"
     ]
    }
   ],
   "source": [
    "print('MAP adaptation of the speaker models')\n",
    "regulation_factor = 16 # MAP regulation factor\n",
    "enroll_sv = enroll_stat.adapt_mean_map_multisession(ubm, regulation_factor)\n",
    "enroll_sv.write('data/sv_enroll.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute trial scores\n"
     ]
    }
   ],
   "source": [
    "print('Compute trial scores')\n",
    "scores_gmm_ubm = sidekit.gmm_scoring(ubm,\n",
    "                                     enroll_sv,\n",
    "                                     test_ndx,\n",
    "                                     features_server,\n",
    "                                     num_thread=nbThread)\n",
    "scores_gmm_ubm.write('scores/scores_gmm-ubm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 60)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubm.mu.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = sidekit.logit_effective_prior(0.01, 1, 1)\n",
    "dp = sidekit.DetPlot(window_style='sre10',\n",
    "                    plot_title=\"GMM-UBM\")\n",
    "dp.set_system_from_scores(scores_gmm_ubm,\n",
    "                         key, sys_name=\"GMM-UBM\")\n",
    "minDCF, Pmiss, Pfa, prebep, EER = sidekit.bosaris.detplot.fast_minDCF(\n",
    "dp.__tar__[0], dp.__non__[0], prior, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UBM-GMM , minDCF = 1.0, eer = 0.30000000000000004\n"
     ]
    }
   ],
   "source": [
    "print(\"UBM-GMM , minDCF = {}, eer = {}\".format(minDCF,EER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv = enroll_sv.stat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.57856716, -0.2062487 , -0.78912706],\n",
       "       [-0.57706275, -0.58023552,  0.57473935],\n",
       "       [-0.57641879,  0.78790115,  0.21668677]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(sv.T)\n",
    "pca.components_.T #固有声"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
